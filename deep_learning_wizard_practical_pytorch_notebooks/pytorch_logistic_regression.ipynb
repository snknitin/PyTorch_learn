{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Logistic Regression with PyTorch\n",
    "## 1. About Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1 Logistic Regression Basics\n",
    "\n",
    "#### Classification algorithm\n",
    "- Example: Spam vs No Spam\n",
    "    - Input: Bunch of words\n",
    "    - Output: Probability spam or not\n",
    "\n",
    "#### Basic Comparison\n",
    "- **Linear regression**\n",
    "    - Output: numeric value given inputs\n",
    "- **Logistic regression**:\n",
    "    - Output: probability [0, 1] given input belonging to a class\n",
    "    \n",
    "    \n",
    "#### Input/Output Comparison\n",
    "- **Linear regression: Multiplication**\n",
    "    - Input: [1]\n",
    "        - Output: 2\n",
    "    - Input: [2]\n",
    "        - Output: 4\n",
    "    - Trying to model the relationship `y = 2x`\n",
    "- **Logistic regression: Spam**\n",
    "    - Input: \"Sign up to get 1 million dollars by tonight\"\n",
    "        - Output: p = 0.8\n",
    "    - Input: \"This is a receipt for your recent purchase with Amazon\"\n",
    "        - Output: p = 0.3\n",
    "    - **p: probability it is spam**\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Problems of Linear Regression\n",
    "- Example\n",
    "    - Fever\n",
    "    - **Input**: temperature\n",
    "    - **Output**: fever or no fever\n",
    "- Remember\n",
    "    - **Linear regression**: minimize error between points and line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCoUDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57c978d0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 100]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 1**\n",
    "<br> Fever value can go negative (below 0) and positive (above 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no1AQEZE6CgUREamjUBARkTr/H3bUwfS1WXS6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57bf90b208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [1, 5, 10, 10, 25, 50, 70, 75, 300]\n",
    "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
    "\n",
    "colors = np.random.rand(len(x))\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.ylabel(\"Fever\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression Problem 2**\n",
    "<br> Fever points not predicted with outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Logistic Regression In-Depth\n",
    "\n",
    "#### Predicting Probability\n",
    "- Linear regression doesn't work\n",
    "- Instead of predicting direct values: **predict probability**\n",
    "\n",
    "<img src=\"./images/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "#### Logistic Function $g()$ \n",
    "- Two-class logistic regression\n",
    "- $ y = A x + b$\n",
    "- $ g(y) = A x + b $\n",
    "- $g(y) = \\frac {1} {1 + e^{-y}} = \\frac {1} {1 + e^{-(A x + b)}}$\n",
    "- $g(y)$ = Estimated probability that $y = 1$ given $x$\n",
    "\n",
    "\n",
    "#### Softmax Function $g()$ \n",
    "- Multi-class logistic regression\n",
    "- Generalization of logistic function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Function $D()$\n",
    "- $D(S, L) = L log S - (1-L)log(1-S)$\n",
    "    - If L = 0 (label)\n",
    "        - $D(S, 0) = - log(1-S)$\n",
    "            - $- log(1-S)$: less positive if $S \\longrightarrow 0 $\n",
    "            - $- log(1-S)$: more positive if $S \\longrightarrow 1 $ (BIGGER LOSS)\n",
    "    - If L = 1 (label)\n",
    "        - $D(S, 1) = log S$\n",
    "            - $logS$: less negative if $S \\longrightarrow 1 $\n",
    "            - $logS$: more negative if $S \\longrightarrow 0 $ (BIGGER LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000050000287824e-05\n",
      "11.51292546497478\n",
      "-1.0000050000287824e-05\n",
      "-11.512925464970229\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(-math.log(1 - 0.00001))\n",
    "print(-math.log(1 - 0.99999))\n",
    "\n",
    "print(math.log(0.99999))\n",
    "print(math.log(0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss $L$\n",
    "- Goal: Minimizing Cross Entropy Loss\n",
    "- $ L = \\frac {1}{N} \\sum_i D(g(Ax_i + b), L_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Logistic Regression Model with PyTorch\n",
    "\n",
    "<img src=\"./images/lr2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
    "\n",
    "### Steps\n",
    "- Step 1: Load Dataset\n",
    "- Step 2: Make Dataset Iterable\n",
    "- Step 3: Create Model Class\n",
    "- Step 4: Instantiate Model Class\n",
    "- Step 5: Instantiate Loss Class\n",
    "- Step 6: Instantiate Optimizer Class\n",
    "- Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a: Loading MNIST Train Dataset\n",
    "**Images from 1 to 9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " (0 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1176\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1922  0.9333\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.8588\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.3137\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0902\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0706  0.6706  0.8588\n",
       "   0.0000  0.0000  0.0000  0.0000  0.2157  0.6745  0.8863  0.9922  0.9922\n",
       "   0.0000  0.0000  0.0000  0.0000  0.5333  0.9922  0.9922  0.9922  0.8314\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 9 to 17 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0118  0.0706  0.0706  0.0706  0.4941  0.5333\n",
       "   0.1412  0.3686  0.6039  0.6667  0.9922  0.9922  0.9922  0.9922  0.9922\n",
       "   0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9922  0.9843\n",
       "   0.9922  0.9922  0.9922  0.9922  0.9922  0.7765  0.7137  0.9686  0.9451\n",
       "   0.6118  0.4196  0.9922  0.9922  0.8039  0.0431  0.0000  0.1686  0.6039\n",
       "   0.0549  0.0039  0.6039  0.9922  0.3529  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.5451  0.9922  0.7451  0.0078  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0431  0.7451  0.9922  0.2745  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.1373  0.9451  0.8824  0.6275  0.4235  0.0039\n",
       "   0.0000  0.0000  0.0000  0.0000  0.3176  0.9412  0.9922  0.9922  0.4667\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.1765  0.7294  0.9922  0.9922\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0627  0.3647  0.9882\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.9765\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.1804  0.5098  0.7176  0.9922\n",
       "   0.0000  0.0000  0.0000  0.1529  0.5804  0.8980  0.9922  0.9922  0.9922\n",
       "   0.0000  0.0941  0.4471  0.8667  0.9922  0.9922  0.9922  0.9922  0.7882\n",
       "   0.2588  0.8353  0.9922  0.9922  0.9922  0.9922  0.7765  0.3176  0.0078\n",
       "   0.9922  0.9922  0.9922  0.9922  0.7647  0.3137  0.0353  0.0000  0.0000\n",
       "   0.9922  0.9922  0.9569  0.5216  0.0431  0.0000  0.0000  0.0000  0.0000\n",
       "   0.5294  0.5176  0.0627  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 18 to 26 \n",
       "    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.6863  0.1020  0.6510  1.0000  0.9686  0.4980  0.0000  0.0000  0.0000\n",
       "   0.8824  0.6745  0.9922  0.9490  0.7647  0.2510  0.0000  0.0000  0.0000\n",
       "   0.3647  0.3216  0.3216  0.2196  0.1529  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0980  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.5882  0.1059  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9922  0.7333  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9922  0.9765  0.2510  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9922  0.8118  0.0078  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.9804  0.7137  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.3059  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "   0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " \n",
       " Columns 27 to 27 \n",
       "    0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       "   0.0000\n",
       " [torch.FloatTensor of size 1x28x28], 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Matrix\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57bf925358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57bf82fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_img = train_dataset[1][0].numpy().reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f57bf82dda0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+5Ke6Lp0ZxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57bf87e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "train_dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Loading MNIST Test Dataset\n",
    "- Show our algorithm works beyond the data we have trained on.\n",
    "- Out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image matrix\n",
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f579a065a20>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUXwFGhz+pWT5yuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57bf9755c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make Dataset Iterable\n",
    "- Aim: make the dataset iterable\n",
    "- **totaldata**: 60000\n",
    "- **minibatch**: 100\n",
    "    - Number of examples in 1 iteration\n",
    "- **iterations**: 3000\n",
    "    - 1 iteration: one mini-batch forward & backward pass\n",
    "- **epochs**\n",
    "    - 1 epoch: running through the whole dataset once\n",
    "    - $epochs = iterations \\div \\frac{totaldata}{minibatch} = 3000 \\div \\frac{60000}{100} = 5 $\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iters = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Iterable Object: Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterable object\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(test_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Aim: Iterate Through Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_1 = np.ones((28, 28))\n",
    "img_2 = np.ones((28, 28))\n",
    "lst = [img_1, img_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Need to iterate\n",
    "# Think of numbers as the images\n",
    "for i in lst:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same as linear regression! \n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Instantiate Model Class\n",
    "- Input dimension: \n",
    "    - Size of image\n",
    "    - $28 \\times 28 = 784$\n",
    "- Output dimension: 10\n",
    "    - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of images\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Instantiate Loss Class\n",
    "- **Logistic Regression**: Cross Entropy Loss\n",
    "    - _Linear Regression: MSE_\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens in `nn.CrossEntropyLoss()`?\n",
    "- Computes softmax (logistic/softmax function)\n",
    "- Computes cross entropy\n",
    "\n",
    "<img src=\"./images/cross_entropy_final_4.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Instantiate Optimizer Class\n",
    "- Simplified equation\n",
    "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
    "        - $\\theta$: parameters (our variables)\n",
    "        - $\\eta$: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_\\theta$: parameters' gradients\n",
    "- Even simplier equation\n",
    "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    - **At every iteration, we update our model's parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters In-Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f57ea04bbf8>\n",
      "2\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# FC 1 Parameters \n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# FC 1 Bias Parameters\n",
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Matrix Product Review\n",
    "- Example 1: **matrix product**\n",
    "    - $A: (100, 10)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A \\cdot B = (100, 10) \\cdot (10, 1) = (100, 1)$\n",
    "- Example 2: **matrix product**\n",
    "    - $A: (50, 5)$\n",
    "    - $B: (5, 2)$\n",
    "    - $A \\cdot B = (50, 5) \\cdot (5, 2) = (50, 2)$\n",
    "- Example 3: **element-wise addition**\n",
    "    - $A: (10, 1)$\n",
    "    - $B: (10, 1)$\n",
    "    - $A + B = (10, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/lr_params2.png\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train Model\n",
    "- Process \n",
    "    1. Convert inputs/labels to variables\n",
    "    2. Clear gradient buffets\n",
    "    3. Get output given inputs \n",
    "    4. Get loss\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradients\n",
    "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    7. REPEAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.880448341369629. Accuracy: 69.78\n",
      "Iteration: 1000. Loss: 1.6356412172317505. Accuracy: 75.98\n",
      "Iteration: 1500. Loss: 1.2981255054473877. Accuracy: 79.27\n",
      "Iteration: 2000. Loss: 1.1125831604003906. Accuracy: 81.14\n",
      "Iteration: 2500. Loss: 1.1944457292556763. Accuracy: 82.26\n",
      "Iteration: 3000. Loss: 0.9866945743560791. Accuracy: 82.92\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break Down Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "Variable containing:\n",
      "-2.3480e-01 -1.1154e+00 -3.7784e-01  ...   2.9690e+00 -2.6889e-01  8.9083e-01\n",
      " 2.6505e-01  1.2975e-01  1.7114e+00  ...  -2.0699e+00  4.4856e-01 -1.6360e+00\n",
      "-9.5328e-01  2.3749e+00  2.1046e-01  ...  -3.4436e-01  1.4159e-01 -3.0560e-01\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0153e+00  1.4910e+00 -6.4334e-01  ...   6.6278e-01  2.5884e-01  6.6621e-01\n",
      " 9.1175e-01 -9.6353e-01  9.6060e-01  ...  -1.0761e+00 -1.3151e-01 -9.1548e-01\n",
      "-1.3626e+00 -1.9472e+00 -5.0706e-03  ...   8.4470e-01  1.6506e-01  2.0812e+00\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs.size())\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS\n",
      "Variable containing:\n",
      "-0.2348\n",
      "-1.1154\n",
      "-0.3778\n",
      "-0.1427\n",
      " 0.0442\n",
      "-0.1986\n",
      "-1.1044\n",
      " 2.9690\n",
      "-0.2689\n",
      " 0.8908\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    if iter_test == 1:\n",
    "        print('OUTPUTS')\n",
    "        print(outputs[0, :])\n",
    "    _, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "\n",
      " 7\n",
      "[torch.LongTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "\n",
      " 7\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[0])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 0')\n",
    "        print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION\n",
      "\n",
      " 2\n",
      "[torch.LongTensor of size 1]\n",
      "\n",
      "LABEL SIZE\n",
      "torch.Size([100])\n",
      "LABEL FOR IMAGE 1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    if iter_test == 1:\n",
    "        print('PREDICTION')\n",
    "        print(predicted[1])\n",
    "        \n",
    "        print('LABEL SIZE')\n",
    "        print(labels.size())\n",
    "        \n",
    "        print('LABEL FOR IMAGE 1')\n",
    "        print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.92\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "iter_test = 0\n",
    "for images, labels in test_loader:\n",
    "    iter_test += 1\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Total number of labels\n",
    "    total += labels.size(0)\n",
    "\n",
    "    # Total correct predictions\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * (correct / total)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ True  True  True  True  True  True  True  True  True  True]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Explaining .sum() python built-in function\n",
    "# correct += (predicted == labels).sum()\n",
    "import numpy as np\n",
    "a = np.ones((10))\n",
    "print(a)\n",
    "b = np.ones((10))\n",
    "print(b)\n",
    "\n",
    "print(a == b)\n",
    "\n",
    "print((a == b).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Logistic Regression Model with PyTorch (GPU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CPU Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.876196026802063. Accuracy: 64.44\n",
      "Iteration: 1000. Loss: 1.5153584480285645. Accuracy: 75.68\n",
      "Iteration: 1500. Loss: 1.3521136045455933. Accuracy: 78.98\n",
      "Iteration: 2000. Loss: 1.2136967182159424. Accuracy: 80.95\n",
      "Iteration: 2500. Loss: 1.0934826135635376. Accuracy: 81.97\n",
      "Iteration: 3000. Loss: 1.024120569229126. Accuracy: 82.49\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as Variable\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "        labels = labels\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # 100 x 10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28).requires_grad_()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                # 100 x 1\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct.item() / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: 2 things must be on GPU\n",
    "- `model`\n",
    "- `variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.8287473917007446. Accuracy: 67.46\n",
      "Iteration: 1000. Loss: 1.4833956956863403. Accuracy: 75.56\n",
      "Iteration: 1500. Loss: 1.3736850023269653. Accuracy: 78.83\n",
      "Iteration: 2000. Loss: 1.223453164100647. Accuracy: 80.68\n",
      "Iteration: 2500. Loss: 0.9830824136734009. Accuracy: 82.05\n",
      "Iteration: 3000. Loss: 1.0098644495010376. Accuracy: 82.82\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = LogisticRegressionModel(input_dim, output_dim)\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, 28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1, 28*28).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    # Bring it back to cpu\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Logistic regression** basics\n",
    "- **Problems** of **linear regression**\n",
    "- **In-depth** Logistic Regression\n",
    "    1. Get logits\n",
    "    2. Get softmax\n",
    "    3. Get cross-entropy loss\n",
    "- **Aim**: reduce cross-entropy loss\n",
    "- Built a **logistic regression model** in **CPU and GPU**\n",
    "    - Step 1: Load Dataset\n",
    "    - Step 2: Make Dataset Iterable\n",
    "    - Step 3: Create Model Class\n",
    "    - Step 4: Instantiate Model Class\n",
    "    - Step 5: Instantiate Loss Class\n",
    "    - Step 6: Instantiate Optimizer Class\n",
    "    - Step 7: Train Model\n",
    "- Important things to be on **GPU**\n",
    "    - `model`\n",
    "    - `tensors with gradients`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
